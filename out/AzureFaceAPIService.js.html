<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <title>JSDoc: Source: AzureFaceAPIService.js</title>

    <script src="scripts/prettify/prettify.js"> </script>
    <script src="scripts/prettify/lang-css.js"> </script>
    <!--[if lt IE 9]>
      <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    <link type="text/css" rel="stylesheet" href="styles/prettify-tomorrow.css">
    <link type="text/css" rel="stylesheet" href="styles/jsdoc-default.css">
</head>

<body>

<div id="main">

    <h1 class="page-title">Source: AzureFaceAPIService.js</h1>

    



    
    <section>
        <article>
            <pre class="prettyprint source linenums"><code>const Err = require("../constant/Error");

class AzureFaceAPIService {

    /**
     * Constructor for AzureFaceAPIService
     */
    constructor() {
        require('dotenv').config();
    }

    /**
     * Returns emotion of current user by processing image to binary and issuing POST request to AzureFaceAPI
     * @param dataURI - image encoding of the user's submitted photo
     * @returns {Promise&lt;* | void>} - returns data regarding user's mood
     */
    getEmotions(dataURI) {
        return this.convertDataURIToBinary(dataURI)
            .then((data) => {
                let axios = require('axios');
                let config = {
                    method: 'post',
                    url: 'https://flowfaceapi.cognitiveservices.azure.com/face/v1.0/detect',
                    headers: {
                        'Ocp-Apim-Subscription-Key': process.env.AZUREKEY,
                        'Content-Type': 'application/octet-stream'
                    },
                    params: {
                        returnFaceID: true,
                        returnFaceLandmarks: false,
                        returnFaceAttributes: 'age,gender,headPose,smile,facialHair,emotion',
                        recognitionModel: 'recognition_03',
                        detectionModel: 'detection_01'
                    },
                    data: data
                };
                return axios(config);
            })
            .then((response) => {
                return this.handleAzureFaceAPIResponse(response);
            })
            .catch((error) => {
                if (error.response &amp;&amp; error.response.data &amp;&amp; error.response.data.error) {
                    throw new Err.AzureFaceApiError(JSON.stringify(error.response.data.error));
                }
                throw error;
            });
    }

    /**
     * Handles response from AzureFaceAPI
     * @param response - emotion data from API response
     * @returns {*} - object with quantities per possible mood
     */
    handleAzureFaceAPIResponse(response) {
        if (!this.isResponseValid(response)) throw new Err.InvalidResponseError("Response from Azure Face API is invalid - null or not an array");
        if (response.data.length === 0) throw new Err.NoUserDetectedError();
        if (!this.isResponseDataValid(response.data)) throw new Err.InvalidResponseError("Response from Azure Face API is invalid - no faceAttributes or emotions");

        let emotionData = response.data[0]["faceAttributes"]["emotion"];
        console.log(JSON.stringify(response.data));
        return emotionData;
    }

    /**
     * Checks if response is valid
     * @param response - response from AzureFaceAPI
     * @returns boolean - returns true if response is not null/undefined and data is an array
     */
    isResponseValid(response) {
        return response &amp;&amp; response.data &amp;&amp; Array.isArray(response.data);
    }

    /**
     * Checks if response data is valid
     * @param responseData - responseData from AzureFaceAPI
     * @returns boolean - returns true if response contains info about faceAttributes and emotions
     */
    isResponseDataValid(responseData) {
        return responseData[0]["faceAttributes"] &amp;&amp; responseData[0]["faceAttributes"]["emotion"];
    }

    /**
     * Converts the data URI image of the user to binary
     * @param dataURI - data URI image of the user
     * @returns {Promise&lt;unknown>} - binary version of image
     */
    convertDataURIToBinary(dataURI) {
        return new Promise((resolve, reject) => {
            if (!dataURI || typeof dataURI !== 'string') return reject(new Err.InvalidInputError("dataURI is formatted improperly"));

            let BASE64_MARKER = ';base64,';
            let base64Index = dataURI.indexOf(BASE64_MARKER) + BASE64_MARKER.length;
            let base64 = dataURI.substring(base64Index);
            let raw = Buffer.from(base64, 'base64').toString("binary");
            let rawLength = raw.length;
            let array = new Uint8Array(new ArrayBuffer(rawLength));

            for (let i = 0; i &lt; rawLength; i++) {
                array[i] = raw.charCodeAt(i);
            }
            return resolve(array);
        });
    }
}

module.exports.AzureFaceAPIService = AzureFaceAPIService;</code></pre>
        </article>
    </section>




</div>

<nav>
    <h2><a href="index.html">Home</a></h2><h3>Classes</h3><ul><li><a href="AzureFaceAPIService.html">AzureFaceAPIService</a></li></ul>
</nav>

<br class="clear">

<footer>
    Documentation generated by <a href="https://github.com/jsdoc/jsdoc">JSDoc 3.6.6</a> on Thu Dec 24 2020 12:49:06 GMT-0800 (Pacific Standard Time)
</footer>

<script> prettyPrint(); </script>
<script src="scripts/linenumber.js"> </script>
</body>
</html>
